# -*- coding: utf-8 -*-
"""MINOR FINALipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AVMXMF_W8KgSKTqMIWhF3XHzrJbyz4gG
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D
from keras.applications import VGG16

from google.colab import drive
drive.mount('/content/drive')

drive.mount("/content/drive", force_remount=True)

!ls '/content/drive'

train_dir = "/content/drive/MyDrive/Data/train"
valid_dir = "/content/drive/MyDrive/Data/test"

img_width, img_height = 130,130 # Default input size for VGG16

conv_base = VGG16(weights='imagenet', 
                  include_top=False,
                  input_shape=(img_width, img_height, 3))

# Show architecture
conv_base.summary()

# Extract features
import os, shutil
from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1./130)
batch_size = 32

def extract_features(directory, sample_count):
    features = np.zeros(shape=(sample_count, 4, 4, 512))  # Must be equal to the output of the convolutional base
    labels = np.zeros(shape=(sample_count,2))
    # Preprocess data
    generator = datagen.flow_from_directory(directory,
                                            target_size=(img_width,img_height),
                                            batch_size = batch_size,
                                            class_mode='categorical')
    # Pass data through convolutional base
    i = 0
    for inputs_batch, labels_batch in generator:
        features_batch = conv_base.predict(inputs_batch)
        features[i * batch_size: (i + 1) * batch_size] = features_batch
        labels[i * batch_size: (i + 1) * batch_size] = labels_batch
        i += 1
        if i * batch_size >= sample_count:
            break
    return features, labels
    
train_features, train_labels = extract_features(train_dir, 359)  # Agree with our small dataset size
validation_features, validation_labels = extract_features(valid_dir, 90)
# test_features, test_labels = extract_features(test_dir, test_size)

train_labels
# print(len(train_labels))

epochs = 20

model = Sequential()
model.add(GlobalAveragePooling2D(input_shape=(4,4,512)))
model.add(Dense(2, activation='softmax'))
model.summary()

from keras.callbacks import ModelCheckpoint
checkpoint = ModelCheckpoint( 'model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5',verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  

# Compile model
from keras.optimizers import Adam
model.compile(optimizer=Adam(),
              loss='categorical_crossentropy',
              metrics=['acc'])

# Train model
history = model.fit(train_features, train_labels,
                    epochs=epochs,
                    batch_size=batch_size)

# Plot results
import matplotlib.pyplot as plt

acc = history.history['acc']

loss = history.history['loss']

epochs = range(1, len(acc)+1)

plt.plot(epochs, acc, 'r', label='Validation accuracy')
plt.title('validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'g', label='Training loss')

plt.title('Training loss')
plt.legend()

plt.show()

from keras.preprocessing import image
def prediction(img_path):
    org_img = image.load_img(img_path)
    img = image.load_img(img_path, target_size=(img_width, img_height))
    img_tensor = image.img_to_array(img)  # Image data encoded as integers in the 0â€“255 range
    img_tensor /= 130.  # Normalize to [0,1] for plt.imshow application
    plt.imshow(org_img)                           
    plt.axis('off')
    plt.show()


    # Extract features
    features = conv_base.predict(img_tensor.reshape(1,img_width, img_height, 3))

    # Make prediction
    try:
        prediction = model.predict(features)
    except:
        prediction = model.predict(features.reshape(1, 4*4*512))
        
    classes = ["Cancerous", "Non-Cancerous"]
    print("This is "+str(classes[np.argmax(np.array(prediction[0]))]))

from tensorflow.keras.preprocessing import image

pred_dir = "/content/drive/MyDrive/Hello/B.png"
import random
prediction(pred_dir)

pred_dir = "/content/drive/MyDrive/Hello/C.png"
import random
prediction(pred_dir)

pred_dir = "/content/drive/MyDrive/Hello/Noncan5.png"
import random
prediction(pred_dir)